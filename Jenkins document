Plugin management 
..................................
var/lib/jenkins-->nextbuildnumber ->file (plugin also we can use) deploy to container (used for tomcat, jboss), weblogic (WAS -> weblogic application support)

websphere Deployer--> to deploy IBM WebSphere Application Server, IBM WebSphere Portal and IBM WebSphere Liberty Profile maven integration

jacoco-->to generate code coverage of java projects
ssh agent
email notification if build fail , success , aborted

ansi colur pulgin for stages view 

audit trail->details of which user trigger, delete, created the job all actions is saved in this

sonarqube scanner--> directly configure in jenkins dashboard
docker also configure with docker registry credientials
and kuberntes also configure 

job config history --> which user config, what cofig, every thing history is stored in this we can restore back old configs also by using restore project option in this plugin
schedule build

blue ocean--> completely changes the gui console of jenkins

pulbish over ssh --> 

ThinBackup --> partial backup of jobs

var/lib/workspace --> default storage for jenkins

Build Name Setter--> custom build name we can set in place of secquence no's
restart

safeRestart -->will complete all running jobs and restart (we can use plugin also)
extrenal plugins installation (browse)

advanced -->used to install external plugins

change default port no
......................................
from 8080 to 9398
cd usr/lib/systemd/system/jenkins.service --> 
change port No
systemctl daemon-reload  -->reload new changes 
Systemctl restart jenkins --> restart jenkins

jenkins security
------------------

create users-->type of access to users-->we give project based authorizatin stategey , LDAP--> view access, build access, admin access, edit view access

provide specific job level access 

go to admin access go to particular job enable project based secuirty (we see only when project based authorizatin stategey is given )
click on add user add user name give required access to them 

project level access 
......................
same as job level access but we give all Access

 back up
.............
thin backup --> used to take jobs,plugins, files etc.. backup for every minute
if we backup now it will create a folder within that minute if we click n no of times on specific minute it will overwrite thats it
back up types--> full backup every time it will take backup, 
differntial backup when ever changes are there then only backup will take
real time backup sst for every 1 hr and 50 backups we take (count may change vary on requirements)

Scripted pipeline
Declarative pipeline

master slave architecture
--------------------------

1 master nodes

2 slave nodes 

in master node only we install jenkins

in all master and slave nodes we install java to execute jobs and git also

if we run job in slave node code is stored in slave node only

if we install global tools in master node it is applicable for slave also

slaves and master can we created in different os also it will work

we can give same label name but name of slave should be unique

slave node working direcory creates

remoting  remoting.jar directories we can see  when node succesfully connected tools workspace --> after 1st run of job it will display directory like var/lib/workspace/


slave creation
----------------

install 1gb ram instance

cd/opt/

install open jdk

create slavel directory

go to master node open manage nodes

click newnode give details

remote root directory is newly created slavel directory path to store jobs we give

launch method (via ssh)

host (public ip of slave)

credientals (ssh user with private key (pem file past))

Now run any job in particular slave or labels by givng name by using restrict where the project can be run option in general section remaining all common

but for pipeline projects we give

agent{

label "slave1"
}

declartive pipeline
-------------------
pipeline{
  agent{
   label "agent1"
  }
  stages{
   stage('build)'{
     steps{
         mvn clean package
     }
   }
   stage('artifact upload'){
     steps{
        nexus Artifactuploader 
     }
   }
  }
 post{
   always{
    cleanws()
    echo "cleaned up workspace"
   }
 }
}


declarative pipeline example
---------------------------
pipeline {
    agent any

    environment {
        // Nexus repository details
        NEXUS_VERSION = 'nexus3'
        NEXUS_PROTOCOL = 'http'
        NEXUS_URL = 'your-nexus-url'
        NEXUS_REPOSITORY = 'your-repo'
        NEXUS_CREDENTIAL_ID = 'your-credentials-id'
        GROUP_ID = 'com.example'
        ARTIFACT_ID = 'myapp'
        VERSION = '1.0.0'
        PACKAGING = 'jar'
    }

    stages {
        stage('Clone Repository') {
            steps {
                git url: 'https://github.com/your-repo.git', branch: 'main'
            }
        }

        stage('Build') {
            steps {
                // Replace with your build steps (e.g., using Maven or Gradle)
                sh 'mvn clean package'
            }
        }

        stage('Upload Artifact to Nexus') {
            steps {
                script {
                    nexusArtifactUploader artifacts: [[
                        artifactId: "${ARTIFACT_ID}",
                        classifier: '',
                        file: "target/${ARTIFACT_ID}-${VERSION}.${PACKAGING}",
                        type: "${PACKAGING}"
                    ]],
                    credentialsId: "${NEXUS_CREDENTIAL_ID}",
                    groupId: "${GROUP_ID}",
                    nexusUrl: "${NEXUS_URL}",
                    nexusVersion: "${NEXUS_VERSION}",
                    protocol: "${NEXUS_PROTOCOL}",
                    repository: "${NEXUS_REPOSITORY}",
                    version: "${VERSION}"
                }
            }
        }
     stage('Deploy into kubernetes cluster'){
        steps{
             script {
                    withCredentials([file(credentialsId: KUBECONFIG_CREDENTIALS, variable: 'KUBECONFIG')]) {
                        sh 'kubectl apply -f k8s/deployment.yaml' 
              }
          }
     }
   
    }

    post {
        always {
            echo 'Cleaning up workspace...'
            cleanWs()
        }
    }
}

Build with Parameter
____________________
we can build one job on differnt environments by using this 
we can select diffrent environments and build at a time by using this option we can reduce disk space also 
In genral ,
click on this project is parmetiezed
give build name
give parmeter type(choice parmeter) add all env like dev ,uat,qa save it
now we can see build with parameters --> select env to run job 

facebook-dev
facebook-qa
facebook-prod
$(params.Propertyname}

jenkins commandline interface
------------------------------
we can control jenkins from commands only its fast and easy way 
we have to create  directory and add jenkins jar file 
we need jenkins-cli.jar file 
we need to integrate a jenkins for communication 
so we give credientals and authenticate it 
java -jar jenkins-cli.jar -auth mithuntechnologies:11ffceb8ea06e043896476ea48c8d46ad8-s

11ffceb8ea06e043896476ea48c8d46ad8

java -jar jenkins-cli.jar -auth mithuntechnologies:11ffceb8ea06e043896476ca48c8d46ad8 -s

http://3.110.42.155:9980 -webSocket list-jobs
for every job we create a shell script to trigger automatically based on requirement 

Migration of jenkins 
--------------------
just copy past old jenkins directory path and configuration files in new jenkins server so all jobs will apper 
(alternative)
job import plugin we have we can import plugin and add  new jenkins directories path to  old jenkins server 

CICD for Node JS Shared Libs

Upstrem Jobs DownStream Jobs
-----------------------------
ex --> we have 3 jobs 
dev --> upstream job for qa
qa --> downstream job for dev & upstream job for prod
prod --> downstream job for qa 
jenkins GUI -->configure --> check box (build after other projects are build) give which projects are to watch list jobs 

Slack Notification
--------------------
we need slack account 
create a channel in it 
in jenkins install slack notificationplugin configure slack channel details 
give for jobs postbuild actions slack notification (check on options we want based on requirement ) so we receive alerts immediately

pipeline examples
=================
agent {
    docker {
        image 'myregistry.com/node'
        label 'my-defined-label'
        registryUrl 'https://myregistry.com/'
        registryCredentialsId 'myPredefinedCredentialsInJenkins'
    }
}


for docker and kubernetes and jenkins nodes we define like this 
agent {
    // Equivalent to "docker build -f Dockerfile.build --build-arg version=1.0.2 ./build/
    dockerfile {
        filename 'Dockerfile.build'
        dir 'build'
        label 'my-defined-label'
        additionalBuildArgs  '--build-arg version=1.0.2'
        args '-v /tmp:/tmp'
    }
}
FOR K8S WE DEFINE LIKE THIS
---------------------------
agent {
    kubernetes {
        defaultContainer 'kaniko'
        yaml '''
kind: Pod
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:debug
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 99d
    volumeMounts:
      - name: aws-secret
        mountPath: /root/.aws/
      - name: docker-registry-config
        mountPath: /kaniko/.docker
  volumes:
    - name: aws-secret
      secret:
        secretName: aws-secret
    - name: docker-registry-config
      configMap:
        name: docker-registry-config
'''
   }

for nodes in jenkins we use like this 
agent {
    node {
        label 'my-defined-label'
        customWorkspace '/some/other/path'
    }
}

THIS IS DECLARATIVE PIPELINE 
pipeline {
    agent any
    stages {
        stage('Example Username/Password') {
            environment {
                SERVICE_CREDS = credentials('my-predefined-username-password')
            }
            steps {
                sh 'echo "Service user is $SERVICE_CREDS_USR"'
                sh 'echo "Service password is $SERVICE_CREDS_PSW"'
                sh 'curl -u $SERVICE_CREDS https://myservice.example.com'
            }
        }
        stage('Example SSH Username with private key') {
            environment {
                SSH_CREDS = credentials('my-predefined-ssh-creds')
            }
            steps {
                sh 'echo "SSH private key is located at $SSH_CREDS"'
                sh 'echo "SSH user is $SSH_CREDS_USR"'
                sh 'echo "SSH passphrase is $SSH_CREDS_PSW"'
            }
        }
    }
}
